{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4YtaQwccjrAL",
        "tOfgGIUtIizt"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_KQBbybK0X"
      },
      "source": [
        "# Homework #3\n",
        "## Introduction to deep learning\n",
        "\n",
        "\n",
        "This colaboratory contains Homework #3 which is due **October 20 midnight (23:59 EET time)**. To complete the homework, extract **(File -> Download .ipynb)** and submit to the course webpage.\n",
        "\n",
        "**NB! Links to your colaboratory will not be accepted as a solution!**\n",
        "## Submission's rules:\n",
        "\n",
        "1.   Please, submit only .ipynb that you extract from the Colaboratory.\n",
        "2. Run your homework exercises before submitting (output should be present, preferably restart the kernel and press run all the cells).\n",
        "3. Do not change the description of tasks in red (even if there is a typo|mistake|etc).\n",
        "4. Please, make sure to avoid unnecessary long printouts.\n",
        "5. Each task should be solved right under the question of the task and not elsewhere.\n",
        "6. Solutions to both regular and bonus exercises should be submitted in one IPYNB file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aE_DE5nx4CJ"
      },
      "source": [
        "##List of Homework's exercises:\n",
        "\n",
        "1.   [Ex1](#scrollTo=4YtaQwccjrAL) - 4 points\n",
        "2.   [Ex2](#scrollTo=tOfgGIUtIizt) - 4 points\n",
        "3.   [Ex3](#scrollTo=rt6Fuo28nQkd) - 2 points\n",
        "4.   [Bonus 1](#scrollTo=wT-4aQqUtDU7) - 2 points\n",
        "5.   [Bonus 2](#scrollTo=lEW4oyQhnRQA) - 2 points\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q-hKuOBzQjU"
      },
      "source": [
        "# A bit of setup\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnapwpH4zRmG"
      },
      "source": [
        "Here we will define few functions that will help us visualise classifiers that we are going to build in this class. Don't worry if you don't understand this code completely."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VjiWNkiW4gd"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# for very shallow models\n",
        "def plot_classifier(X, y, W, b):\n",
        "  st = 0.02\n",
        "  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, st),\n",
        "                       np.arange(y_min, y_max, st))\n",
        "  Z = np.dot(np.c_[xx.ravel(), yy.ravel()], W) + b\n",
        "  Z = np.argmax(Z, axis=1)\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  fig = plt.figure()\n",
        "  plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=120, edgecolors = 'white', cmap=plt.cm.Spectral)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())\n",
        "\n",
        "# for two-layer network\n",
        "def plot_neural_network(X, y, W,b ,W2, b2):\n",
        "  st = 0.02\n",
        "  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, st),\n",
        "                       np.arange(y_min, y_max, st))\n",
        "  Z = np.dot(np.maximum(0, np.dot(np.c_[xx.ravel(), yy.ravel()], W) + b), W2) + b2\n",
        "  Z = np.argmax(Z, axis=1)\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  fig = plt.figure()\n",
        "  plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=120, edgecolors = 'white', cmap=plt.cm.Spectral)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKUSZLZsW5lV"
      },
      "source": [
        "N = 100 # number of points per class\n",
        "D = 2 # number of features (dimensions)\n",
        "K = 2 # number of classes (purple and red circles)\n",
        "X = np.zeros((N*K,D)) # data matrix (each row = single example)\n",
        "num_examples = X.shape[0]\n",
        "y = np.zeros((N*K, 1), dtype='int') # class labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy2fvNGHFmlk"
      },
      "source": [
        "# Creating spiral data points\n",
        "np.random.seed(1111)\n",
        "\n",
        "for j in range(K):\n",
        "  ix = range(N*j,N*(j+1))\n",
        "  r = np.linspace(0.0,1,N) # radius\n",
        "  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
        "  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "  y[ix, 0] = j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLuE6wP_ArUT"
      },
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=120, edgecolors = 'white', cmap=plt.cm.Spectral)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3NtwiWdHmk1"
      },
      "source": [
        "For our implementation we would need to transform the vector of correct labels `y` into one hot encoded matrix, let's call it `truth`. Сreating `truth` as one-hot encoded labels (`y`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8KrB0QT_hn6"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "truth = enc.fit_transform(y).toarray()\n",
        "\n",
        "# first column is for red\n",
        "# second is for purple class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YtaQwccjrAL"
      },
      "source": [
        "## Homework exercise 1 (4 points): three-layer network\n",
        " <font color='red'>In the class we have obtained ~94% using 2-layer neural network when classifying points in spiral. This is surely not good enough for us. Hence, let's make a few tweaks in attempt to reach higher performance.</font>\n",
        "\n",
        "<font color='red'>**PS: Before you start working on this task, please read it in its entirety!**</font>\n",
        "\n",
        "<font color='red'> **(a)** Based on the code we have written in the practice session, build a new 3-layer neural network, consiting two hidden layers (each of size `h`) and one output layer. Using ChatGPT/Gemini will likely result in architectures which are substantially different from what we intended, so try to follow the code provided in the practice session. Use `tanh` as an activation function for the hidden layers. Compute both feedforward and backpropagation paths to update the model weights and produce predictions (you might want to check out [this post](https://medium.com/@Coursesteach/deep-learning-part-25-derivatives-of-activation-functions-4bbd7c7c7a1c) about the derivatives of the most popular activation functions). Answer a question at the end of this subtask. **(1.5 points)**. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcFDKdEMj0hZ"
      },
      "source": [
        "np.random.seed(111)\n",
        "num_examples = X.shape[0]\n",
        "\n",
        "# Initialize parameters randomly\n",
        "h = 100  # Size of hidden layer\n",
        "W = np.random.randn(D,h)\n",
        "b = np.zeros((1,h))\n",
        "W2 = np.random.randn(h,h)\n",
        "b2 = np.zeros((1,h))\n",
        "W3 = np.random.randn(h,K)\n",
        "b3 = np.zeros((1,K))\n",
        "\n",
        "# Some hyperparameters\n",
        "step_size = 1e-0\n",
        "\n",
        "# Gradient descent loop\n",
        "##### YOUR CODE STARTS #####\n",
        "for i in range(2000):\n",
        "\n",
        "  # Forward path\n",
        "  ...\n",
        "\n",
        "  # Compute the error\n",
        "  ...\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    print(\"iteration %d: loss %e\" % (i, total_error))\n",
        "\n",
        "  # Compute the gradient on answers\n",
        "  ...\n",
        "\n",
        "  # Backpropagate the gradient to the parameters\n",
        "  ...\n",
        "\n",
        "  # Perform a parameter update\n",
        "  ...\n",
        "\n",
        "  ##### YOUR CODE ENDS #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> If you have implemented everything correctly, you should have encountered a problem :)\n",
        "Below name the problem and describe why it happens: </font>"
      ],
      "metadata": {
        "id": "EVFLaFDPuPuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> Your answer: </font>"
      ],
      "metadata": {
        "id": "M2_gsOBa1Q8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **(b)** Fix the issue you have encountered above using one of the ideas that we have discussed in the lecture. Please, insert and run the updated code in the cell below. **(1.5 points)**. </font>"
      ],
      "metadata": {
        "id": "PDfHZ2dOuf8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "uIO6Fkzzu0dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> If it worked fine, evaluate your model running the code below. </font>"
      ],
      "metadata": {
        "id": "6DCj1bQbvvCk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXMOSa1j_s4v"
      },
      "source": [
        "#evaluate training set accuracy\n",
        "hidden_layer = np.tanh(np.dot(X, W) + b)\n",
        "hidden_layer_2 = np.tanh(np.dot(hidden_layer, W2) + b2) # NB, tanh activation\n",
        "answers = np.dot(hidden_layer_2, W3) + b3 # Note, no activation function for the last layer!\n",
        "predicted_class = np.argmax(answers, axis=1)\n",
        "print('training accuracy: %.2f' % (np.mean(predicted_class == y[:,0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz5aYjIiy0e4"
      },
      "source": [
        "<font color='red'> You should get about 98% of accuracy or more... </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOxoCy6U1psH"
      },
      "source": [
        "<font color='red'> **(c)** Update function `plot_deep_neural_network` by altering the code of `plot_neural_network` to visualise obtained 3-layer network with `tanh` activation function. Visualise obtained decision boundary. How did it change comparing to the one we have observed by 2-layer models? Do you think you would be able to easily get 100% for this data? **(1 point)** </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efjki_p7yy3i"
      },
      "source": [
        "def plot_deep_neural_network(X, y, W, b ,W2, b2, W3, b3):\n",
        "  h = 0.02\n",
        "  x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "  y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                       np.arange(y_min, y_max, h))\n",
        "\n",
        "  ##### YOUR CODE STARTS #####\n",
        "  Z = ...\n",
        "  ##### YOUR CODE ENDS #####\n",
        "\n",
        "  Z = np.argmax(Z, axis=1)\n",
        "  Z = Z.reshape(xx.shape)\n",
        "  fig = plt.figure()\n",
        "  plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
        "  plt.scatter(X[:, 0], X[:, 1], c=y, s=120, edgecolors = 'white', cmap=plt.cm.Spectral)\n",
        "  plt.xlim(xx.min(), xx.max())\n",
        "  plt.ylim(yy.min(), yy.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WijEV8LsyjxE"
      },
      "source": [
        "# plot the resulting classifier\n",
        "plot_deep_neural_network(X, y, W, b, W2, b2, W3, b3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSfviya2Ep4m"
      },
      "source": [
        "<font color='red'> Answer to **(c)**: </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOfgGIUtIizt"
      },
      "source": [
        "## Homework exercise 2 (4 points): balancing model complexity and performance\n",
        "<font color='red'> In this exercise, you’re going to explore how we can balance model size and performance in neural networks. The goal of this exercise is to help you understand the relationship between model complexity, resource usage, and performance.  </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5edn09iAfyye"
      },
      "source": [
        "# A bit of setup again\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout\n",
        "\n",
        "# Keras comes with built-in loaders for common datasets\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# shorten dataset for quicker training\n",
        "X_train = X_train[:50000]\n",
        "y_train = y_train[:50000]\n",
        "\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovI_f2Vif_ot"
      },
      "source": [
        "mu = X_train.mean(axis=(0,1,2)) # finds mean of R, G and B separately\n",
        "std = X_train.std(axis=(0,1,2)) # same for std\n",
        "X_train_norm = (X_train - mu)/std\n",
        "X_test_norm = (X_test - mu)/std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<font color='red'> **(a)** Take a CNN model created for CIFAR-10 from the practice session and copy it below.\n",
        "\n",
        "<font color='red'>Compute and report the following properties:\n",
        "<font color='red'>\n",
        "<ol>\n",
        "  <li>Number of model parameters</li>\n",
        "  <li>Memory used by the model parameters\n",
        "  <li>Training and inference times</li>\n",
        "  <li>Accuracy on the training and test set</li>\n",
        "</ol>\n",
        "</font>\n",
        "\n",
        "<font color='red'> Additionally, visualize the learning curves (loss and accuracy over epochs). (**0.5 points**)\n",
        "\n",
        "</font>"
      ],
      "metadata": {
        "id": "9jTKEzRuBCnE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuT5KRQh8JL2"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "# you might want to use several cells\n",
        "##### YOUR CODE ENDS #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the learning curves\n",
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "WY5ONBfSxXTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the properties\n",
        "###### YOUR CODE STARTS #####\n",
        "print(f\"Number of parameters: ...\")\n",
        "print(f\"Memory usage for the model parameters: ... \")\n",
        "print(f\"Training time: ... \")\n",
        "print(f\"Inference time: ... \")\n",
        "print(f\"Accuracy on the training set: ...\")\n",
        "print(f\"Accuracy on the test set: ...\")\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "ix_ZOYZsrRbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcBGJvDOg-QP"
      },
      "source": [
        "<font color='red'> **(b)** Now, create a new model with approximately twice the number of parameters as the previous one, aiming for higher accuracy. You might consider adding layers, or tweaking the existing ones. Report the same properties as in **(a)**. Do not forget to visualize the learning curves. (**1.5 points**) </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRWpixQ1G-qX"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "# you might want to use several cells\n",
        "##### YOUR CODE ENDS #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the learning curves\n",
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "-xhOFc6PxiQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the properties\n",
        "###### YOUR CODE STARTS #####\n",
        "print(f\"Number of parameters: ...\")\n",
        "print(f\"Memory usage for the model parameters: ... \")\n",
        "print(f\"Training time: ... \")\n",
        "print(f\"Inference time: ... \")\n",
        "print(f\"Accuracy on the training set: ...\")\n",
        "print(f\"Accuracy on the test set: ...\")\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "l3CYXejcrmHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB9b7aVuj4O1"
      },
      "source": [
        "<font color='red'> **(c)** Finally, create a third model with approximately the same number of parameters as the initial baseline model, but aim for accuracy that matches or even exceeds the second (larger) model. Report the same properties and visualize the learning curves for this model. (**1.5 points**)\n",
        "\n",
        "HINT: To get higher accuracy, focus on applying techniques you have learned from the lecture and practice sessions.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "# you might want to use several cells\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "tMloNRhzru2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the learning curves\n",
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "ndiZbGi9xjRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the properties\n",
        "###### YOUR CODE STARTS #####\n",
        "print(f\"Number of parameters: ...\")\n",
        "print(f\"Memory usage for the model parameters: ... \")\n",
        "print(f\"Training time: ... \")\n",
        "print(f\"Inference time: ... \")\n",
        "print(f\"Accuracy on the training set: ...\")\n",
        "print(f\"Accuracy on the test set: ...\")\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "yRIpVnRIrxgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='red'> **(d)** Summarise all key properties (such as number of parameters and memory usage) of all three models in a single neat table! Also, additionally add a figure with all three pairs of learning curves (perhaps, using a different panel for each pair of curves). Explain how changes in the architecture affected the behaviour of all three models during training and inference. Which model would you choose for real-world use? Feel free to discuss different use cases. (**0.5 points**)\n",
        "</font>"
      ],
      "metadata": {
        "id": "a6yqxJEvr6iD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_ogpcrTmjPV"
      },
      "source": [
        "<font color='red'>  Answer to **(d)**: </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt6Fuo28nQkd"
      },
      "source": [
        "## Homework exercise 3 (2 points): Create your own dataset and build a CNN model using fast.ai API\n",
        "<font color='red'> In this exercise, you have a chance to test if CNN can distinguish between images of your favourite objects. </font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastai==1.0.61"
      ],
      "metadata": {
        "id": "pYbxevNzK5Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtDvypikm6gX"
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMWYNE5Sm8jt"
      },
      "source": [
        "<font color='red'> **(a)** Create your own dataset with two or more classes using the same approach we used in the class. But this time choose classes yourself. **(1 point)** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRW-9KvbnP0s"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "metadata": {
        "id": "VHJjFO90pPLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VecNOB6T2rE1"
      },
      "source": [
        "# add more cells as necessary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3LouVIGnzal"
      },
      "source": [
        "<font color='red'> **(b)** train a neural network on images you have acquired **(0.5 points)** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcZzq166qt12"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "learn = ...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKvDscRYrK_m"
      },
      "source": [
        "Plot the confusion matrix to make sure that you model has learned something:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNL5-zivrPlc"
      },
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg7WWu2Kn4MJ"
      },
      "source": [
        "<font color='red'> **(c)** Test your model on one or more images from the internet that represent classes you have chosen, but unlikely to be in the training data (you can change your search query). Print out class probabilities for one of these test images. **(0.5 points)** </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WHB8idjvoV7"
      },
      "source": [
        "##### YOUR CODE STARTS #####\n",
        "img = ...\n",
        "img\n",
        "##### YOUR CODE ENDS #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpS8bQelslTW"
      },
      "source": [
        "# What are the probabilities of different classes for this image?\n",
        "##### YOUR CODE STARTS #####\n",
        "...\n",
        "##### YOUR CODE ENDS #####"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYV0-7KkIH7e"
      },
      "source": [
        "# Bonus exercises\n",
        "*(NB, these are optional exercises!)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT-4aQqUtDU7"
      },
      "source": [
        "## Bonus exercise 1 (2 bonus points):\n",
        "\n",
        "<font color='red'> [Stable Diffusion](https://stability.ai/blog/stable-diffusion-announcement) model has been recently shown to produce trully impressive results in image generation. Let's explore some of its power in this auxiliarly exercise. Use Stable Diffusion model from this [colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb?hl=en). Generate several tricky images to test the model you trained in the exercise 3. Report the images that you have generated with Stable Diffusion, prompt that you have used for generating them, the number of iterations that you used to generate images and the classification results from your CNN model. Shortly summarise the results you have obtained. </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEW4oyQhnRQA"
      },
      "source": [
        "## Bonus exercise 2 (2 bonus points):\n",
        "\n",
        "<font color='red'> [Pytorch](https://pytorch.org/) is another widely used and deeply loved deep learning library. In this task, you will get a chance to try it out. Firstly, re-implement one of the CNNs you were working with in EX 2 (or you can try a different architecture) in Pytorch. Train and validate the model on the dataset you collected in EX3. Secondly, use a ResNet model from [torchhub](https://pytorch.org/docs/stable/hub.html) and train it on the same data. Compare the results of these two models and the one from fastai library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JZfcKFAs82h"
      },
      "source": [
        "# Comments (optional feedback to the course instructors)\n",
        "Here, please, leave your comments regarding the homework, possibly answering the following questions:\n",
        "* how much time did you spend on this homework?\n",
        "* was it too hard/easy for you?\n",
        "* what would you suggest to add or remove?\n",
        "* anything else you would like to tell us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22VPt-05s-Yg"
      },
      "source": [
        "Your comments:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>  End of the homework. Please don't delete this cell.</font>"
      ],
      "metadata": {
        "id": "_VXRWrUnCnyQ"
      }
    }
  ]
}